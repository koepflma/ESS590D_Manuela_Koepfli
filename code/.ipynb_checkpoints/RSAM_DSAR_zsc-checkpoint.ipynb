{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e29a6a",
   "metadata": {},
   "source": [
    "# z-score normalization & csv files for plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4d4243c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1a21c4c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define functions\n",
    "def zsc(s):\n",
    "    '''z-score normaliztion in log space (Ardid et al., 2022)'''\n",
    "    # log transform data\n",
    "    log_s = np.log10(s).replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    \n",
    "    # compute mean/std/min\n",
    "    mn = np.mean(log_s)\n",
    "    std = np.std(log_s)\n",
    "    minzsc = np.min(log_s)                                                    \n",
    "\n",
    "    # Calculate percentile\n",
    "    s=(np.log10(s)-mn)/std\n",
    "    s=s.fillna(minzsc)\n",
    "    s=10**s\n",
    "    return s\n",
    "\n",
    "def zsc2(s):\n",
    "    '''apply z-score normalization with rolling'''\n",
    "    s=zsc(s)\n",
    "    s=s.rolling(window=2).min()\n",
    "    s[0]=s[1]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1377a446",
   "metadata": {},
   "source": [
    "## Add z-score normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "127dc5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CDF\n",
      "SEP\n",
      "VALT\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "No objects to concatenate",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m     frame \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(filename) \u001b[38;5;66;03m# read one day\u001b[39;00m\n\u001b[1;32m     16\u001b[0m     li\u001b[38;5;241m.\u001b[39mappend(frame) \u001b[38;5;66;03m# all days (one year) of one station\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mli\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# list to df\u001b[39;00m\n\u001b[1;32m     19\u001b[0m df\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime\u001b[39m\u001b[38;5;124m'\u001b[39m,inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;66;03m# index to time\u001b[39;00m\n\u001b[1;32m     20\u001b[0m df\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mto_datetime(df\u001b[38;5;241m.\u001b[39mindex)\u001b[38;5;241m.\u001b[39mtz_localize(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;66;03m# time to datetime\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/seismo/lib/python3.8/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/seismo/lib/python3.8/site-packages/pandas/core/reshape/concat.py:368\u001b[0m, in \u001b[0;36mconcat\u001b[0;34m(objs, axis, join, ignore_index, keys, levels, names, verify_integrity, sort, copy)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconcat\u001b[39m(\n\u001b[1;32m    148\u001b[0m     objs: Iterable[NDFrame] \u001b[38;5;241m|\u001b[39m Mapping[HashableT, NDFrame],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    157\u001b[0m     copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    158\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[1;32m    159\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    160\u001b[0m \u001b[38;5;124;03m    Concatenate pandas objects along a particular axis.\u001b[39;00m\n\u001b[1;32m    161\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[38;5;124;03m    1   3   4\u001b[39;00m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 368\u001b[0m     op \u001b[38;5;241m=\u001b[39m \u001b[43m_Concatenator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m        \u001b[49m\u001b[43mobjs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m        \u001b[49m\u001b[43mjoin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    375\u001b[0m \u001b[43m        \u001b[49m\u001b[43mnames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    376\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverify_integrity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverify_integrity\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m        \u001b[49m\u001b[43msort\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msort\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    379\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    381\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[0;32m~/anaconda3/envs/seismo/lib/python3.8/site-packages/pandas/core/reshape/concat.py:425\u001b[0m, in \u001b[0;36m_Concatenator.__init__\u001b[0;34m(self, objs, axis, join, keys, levels, names, ignore_index, verify_integrity, copy, sort)\u001b[0m\n\u001b[1;32m    422\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(objs)\n\u001b[1;32m    424\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(objs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 425\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo objects to concatenate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    428\u001b[0m     objs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(com\u001b[38;5;241m.\u001b[39mnot_none(\u001b[38;5;241m*\u001b[39mobjs))\n",
      "\u001b[0;31mValueError\u001b[0m: No objects to concatenate"
     ]
    }
   ],
   "source": [
    "# year = 2009\n",
    "#============================================================================================\n",
    "\n",
    "for year in range(2000,2022+1):\n",
    "    # calculate z-score normalization and save one file per station\n",
    "#     all_files = sorted(glob.glob('/data/wsd03/data_manuela/MtStHelens/RSAM_DSAR/tmp_{}/*/*.csv'.format(year)))\n",
    "#     sta_list = np.unique([file.split('/')[-2] for file in all_files]) # station list based on the files\n",
    "    sta_list = ['CDF','SEP','VALT','HOA','LOO','USFR','REM','SWFL','SFW2']\n",
    "    for sta in sta_list:\n",
    "        print(sta)\n",
    "        # all days (one year) of one station\n",
    "        sta_files = sorted(glob.glob('/data/wsd03/data_manuela/MtStHelens/RSAM_DSAR/tmp_{}/{}/*.csv'.format(year,sta)))\n",
    "        if sta_files \n",
    "        li = [] # empty list\n",
    "        for filename in sta_files:\n",
    "            frame = pd.read_csv(filename) # read one day\n",
    "            li.append(frame) # all days (one year) of one station\n",
    "\n",
    "        df = pd.concat(li, axis=0, ignore_index=True) # list to df\n",
    "        df.set_index('time',inplace=True) # index to time\n",
    "        df.index = pd.to_datetime(df.index).tz_localize(None) # time to datetime\n",
    "        df.sort_index() # sort by date (index)\n",
    "\n",
    "        # compute transform for each column (time series)\n",
    "        df['zsc2_rsam'] = zsc2(df['rsam'])\n",
    "        df['zsc2_mf'] = zsc2(df['mf'])\n",
    "        df['zsc2_hf'] = zsc2(df['hf'])\n",
    "        df['zsc2_dsar'] = zsc2(df['dsar'])\n",
    "        df['zsc2_ldsar'] = zsc2(df['ldsar'])\n",
    "        df['zsc2_vsar'] = zsc2(df['vsar'])\n",
    "        df['zsc2_rms'] = zsc2(df['rms'])\n",
    "        df['zsc2_rmes'] = zsc2(df['rmes'])\n",
    "        df['zsc2_pgv'] = zsc2(df['pgv'])\n",
    "        df['zsc2_pga'] = zsc2(df['pga'])\n",
    "\n",
    "        df.to_csv('/home/koepflma/project1/Mt-St-Helens/RSAM_DSAR/data/{}_{}_extended2.csv'.format(year,sta)) # save csv file with z-score normalization\n",
    "    #     df.to_csv('../{}_{}_extended2.csv'.format(year,sta)) # save csv file with z-score normalization\n",
    "    print('***{} done***'.format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "baf9ed6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "empty\n"
     ]
    }
   ],
   "source": [
    "if sta_files:\n",
    "    print('not empty')\n",
    "else:\n",
    "    print('empty')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e05f37",
   "metadata": {},
   "source": [
    "## Create multi-year long files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "288ea395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2000_SEP_extended2.csv', '2001_SEP_extended2.csv', '2002_SEP_extended2.csv', '2003_SEP_extended2.csv', '2004_SEP_extended2.csv', '2005_SEP_extended2.csv', '2006_SEP_extended2.csv', '2007_SEP_extended2.csv', '2008_SEP_extended2.csv', '2009_SEP_extended2.csv', '2010_SEP_extended2.csv', '2011_SEP_extended2.csv', '2012_SEP_extended2.csv', '2013_SEP_extended2.csv', '2014_SEP_extended2.csv', '2015_SEP_extended2.csv', '2016_SEP_extended2.csv', '2017_SEP_extended2.csv', '2018_SEP_extended2.csv', '2019_SEP_extended2.csv', '2020_SEP_extended2.csv', '2021_SEP_extended2.csv', '2022_SEP_extended2.csv']\n",
      "***done***\n"
     ]
    }
   ],
   "source": [
    "sta = 'SEP'\n",
    "#============================================================================================\n",
    "# notice, you already need the extended2.csv file for the station\n",
    "all_files = sorted(glob.glob('/home/koepflma/project1/Mt-St-Helens/RSAM_DSAR/data/*_{}_extended2.csv'.format(sta)))\n",
    "print([file.split('/')[-1] for file in all_files]) # check how many years you have\n",
    "li = [] # empty list\n",
    "for filename in all_files:\n",
    "    frame = pd.read_csv(filename) # read one year\n",
    "    li.append(frame) # all years of one station\n",
    "\n",
    "df = pd.concat(li, axis=0, ignore_index=True) # list to df\n",
    "df.set_index('time',inplace=True) # index to time\n",
    "df.index = pd.to_datetime(df.index).tz_localize(None) # time to datetime\n",
    "df.sort_index() # sort by date (index)\n",
    "df.to_csv('/home/koepflma/project1/Mt-St-Helens/RSAM_DSAR/data/{}_extended2_long2.csv'.format(sta)) # save csv file with multiple years of one station\n",
    "print('***done***')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "37a67dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4],\n",
       "       [1, 2, 3, 4]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n1 = np.array([np.array([1,2,3,4]),np.array([1,2,3,4])])\n",
    "n1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c2d242",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
